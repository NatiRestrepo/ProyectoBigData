{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{ \"conf\":{\n",
    "\"spark.pyspark.python\": \"python3\",\n",
    "\"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "\"spark.pyspark.virtualenv.type\":\"native\",\n",
    "\"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e103a7ee341e4ae7b4d7787de7887649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1574276126980_0006</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-92-81.ec2.internal:20888/proxy/application_1574276126980_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-92-179.ec2.internal:8042/node/containerlogs/container_1574276126980_0006_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /var/lib/livy/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /var/lib/livy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ff0bc0e9da4e9d8af7333de0bc9b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package already installed for current Spark context!\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py\", line 1110, in install_pypi_package\n",
      "    raise ValueError(\"Package already installed for current Spark context!\")\n",
      "ValueError: Package already installed for current Spark context!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package('pandas')\n",
    "#sc.install_pypi_package('nltk')\n",
    "sc.install_pypi_package('tqdm')\n",
    "sc.install_pypi_package('Ipython')\n",
    "sc.install_pypi_package('tabulate')\n",
    "sc.install_pypi_package('boto3')\n",
    "sc.install_pypi_package('scipy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fe313f3d3b49de8ca29b7082440c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os, csv, glob, json, uuid, pickle, math\n",
    "import nltk\n",
    "import numpy as np, scipy, pandas as pd\n",
    "from operator import itemgetter\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "from tqdm import tqdm\n",
    "from pyspark.ml.feature import Word2Vec, Word2VecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c58e75bd82a42bdbae497197b9f74c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bucketName = 'taller4'\n",
    "URI = sc._gateway.jvm.java.net.URI\n",
    "Path = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "FileSystem = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "fs = FileSystem.get(URI(\"s3://\"+bucketName), sc._jsc.hadoopConfiguration())\n",
    "\n",
    "# We can now use the Hadoop FileSystem API (https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html)\n",
    "#fs.listStatus(Path('/user/njaram15/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e67848b30ff439d8ede1c5428b54a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CONTENT_INDEX = 9\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "CONTENT_PATH = '/tallerTextMining/inputs/contents/'\n",
    "TOKENS_PATH = '/tallerTextMining/inputs/tokens/'\n",
    "CENTROIDS_PATH = '/tallerTextMining/inputs/centroids/'\n",
    "MODEL_PATH = '/tallerTextMining/model/'\n",
    "\n",
    "#fs.mkdirs(Path(CONTENT_PATH))\n",
    "#fs.mkdirs(Path(TOKENS_PATH))\n",
    "#fs.mkdirs(Path(CENTROIDS_PATH))\n",
    "#fs.mkdirs(Path(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8079d658218a49e89c843d00f41aff02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.csv('s3://'+bucketName+'/tallerTextMining/inputs/*.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b9e0dbda0d4fa5b98ae92c3b6d1997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999"
     ]
    }
   ],
   "source": [
    "len(df.rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b153d0bdb20a443cb3502fe8c7281c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for line in df.rdd.collect():\n",
    "    count = count + 1\n",
    "    content = line['content']\n",
    "    cname = CONTENT_PATH + str(count) + '.txt'\n",
    "    tname = TOKENS_PATH + str(count) + '.tokens'\n",
    "    #write_s3file(cname,content)\n",
    "    if not fs.exists(Path('s3://'+bucketName+cname)):\n",
    "        sc.parallelize([content]).saveAsTextFile('s3://'+bucketName+cname)    \n",
    "    sentences = \"\"\n",
    "    for sentence in nltk.sent_tokenize(content):\n",
    "        sentences = sentences + sentence.lower() + \"\\n\"\n",
    "\n",
    "    #write_s3file(tname, sentences)\n",
    "    if not fs.exists(Path('s3://'+bucketName+tname)):\n",
    "        sc.parallelize([sentences]).saveAsTextFile('s3://'+bucketName+tname)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3181ccb5953456fbf2c5899d9400b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "def cleanStopWordAndStemming(sentences):\n",
    "    stop_words = stopwords.words('english')\n",
    "    stemmer = PorterStemmer()\n",
    "    sen = []\n",
    "    for sentence in sentences:\n",
    "        senten = [word for word in sentence if word not in stop_words]\n",
    "        singles = [stemmer.stem(token) for token in senten]\n",
    "        sen.append(singles)\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d7979d065646789a1b37d36f1d6a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = []\n",
    "df2 = spark.read.text('s3://'+bucketName+'/tallerTextMining/inputs/tokens/*.tokens')\n",
    "for line in df2.collect():\n",
    "    sentences.append(nltk.word_tokenize(line['value'].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec02d4b123404af3a4f24ee929969611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joachim', 'neander', 'calvinist', 'theologian', 'often', 'hike', 'valley', 'outsid', 'düsseldorf', ',', 'germani', ',', 'write', 'hymn', '.']"
     ]
    }
   ],
   "source": [
    "sentences = cleanStopWordAndStemming(sentences)\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8778d97195d44f909cf0c23f2df61d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|       word|              vector|\n",
      "+-----------+--------------------+\n",
      "|    rahmani|[-0.0112890955060...|\n",
      "|      brink|[0.11128488183021...|\n",
      "|   promenad|[0.09507359564304...|\n",
      "|    acronym|[0.04120612144470...|\n",
      "|  forgotten|[0.13175040483474...|\n",
      "|     justif|[-0.2294008284807...|\n",
      "|     teresa|[-0.0794001594185...|\n",
      "|      lover|[0.09871610999107...|\n",
      "|     comedi|[0.13516199588775...|\n",
      "|  regularli|[0.18409946560859...|\n",
      "|      fanci|[0.06045890972018...|\n",
      "|       elit|[0.39351123571395...|\n",
      "|    speaker|[-0.2253546267747...|\n",
      "|       chee|[0.12783752381801...|\n",
      "|       lion|[0.06552257388830...|\n",
      "|       rate|[0.63716894388198...|\n",
      "|     pepper|[0.09586166590452...|\n",
      "|       2014|[0.15399555861949...|\n",
      "|uncertainti|[0.15482957661151...|\n",
      "|nonetheless|[0.03948763385415...|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "inputs = [(x,) for x in sentences]\n",
    "doc = spark.createDataFrame(inputs, [\"sentence\"])\n",
    "word2Vec = Word2Vec(vectorSize=5, seed=42, inputCol=\"sentence\", outputCol=\"model\")\n",
    "model = word2Vec.fit(doc)\n",
    "model.getVectors().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1945d1e4385841cb90f786328bb2d9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not fs.exists(Path('s3://'+bucketName+'/tallerTextMining/model/word2vec-model')):\n",
    "    model.save('s3://'+bucketName+'/tallerTextMining/model/word2vec-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d43bdbcf8944f1aae86534fc68def7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = None\n",
    "model = Word2VecModel.load('s3://'+bucketName+'/tallerTextMining/model/word2vec-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e262cb4075c44ad9967f639a2d12497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = model.getVectors().select('word').collect()\n",
    "vocab = dict([(v.word, k) for k, v in enumerate(words)])\n",
    "#write_s3file('taller2/model/w2v-lc-vocab.json', json.dumps(vocab))\n",
    "if not fs.exists(Path('s3://'+bucketName+'/tallerTextMining/model/w2v-lc-vocab.json')):\n",
    "    sc.parallelize([json.dumps(vocab)]).saveAsTextFile('s3://'+bucketName+'/tallerTextMining/model/w2v-lc-vocab.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fa9d6d7ece48cf8655c8769a29df82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|        word|similarity|\n",
      "+------------+----------+\n",
      "|      mother|   1.00000|\n",
      "|          tv|   0.99624|\n",
      "|      jacket|   0.99155|\n",
      "|        movi|   0.99134|\n",
      "|       whole|   0.98891|\n",
      "|      sitcom|   0.98794|\n",
      "|       baton|   0.98666|\n",
      "|        song|   0.98525|\n",
      "|      runway|   0.98351|\n",
      "|totalitarian|   0.98344|\n",
      "+------------+----------+"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number as fmt\n",
    "\n",
    "vectors = model.getVectors()\n",
    "t = vectors.filter(vectors.word == 'mother').select('vector').collect()[0]['vector']\n",
    "# como senate y alabama no están en el dataset de prueba se simulan con ceros\n",
    "s = np.array([0.0,0.0,0.0,0.0,0.0])\n",
    "a = np.array([0.0,0.0,0.0,0.0,0.0])\n",
    "r = t+s-a\n",
    "# r = a-t+s\n",
    "model.findSynonyms(r, 10).select(\"word\", fmt(\"similarity\", 5).alias(\"similarity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b030c5e77b654f91b55677262b8cdd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               value|            filename|\n",
      "+--------------------+--------------------+\n",
      "|Joachim Neander w...|s3://taller4/tall...|\n",
      "|WASHINGTON  —   W...|s3://taller4/tall...|\n",
      "|When Indira Islas...|s3://taller4/tall...|\n",
      "|On the morning of...|s3://taller4/tall...|\n",
      "|In the fall of 20...|s3://taller4/tall...|\n",
      "|Hours before the ...|s3://taller4/tall...|\n",
      "|President Obama d...|s3://taller4/tall...|\n",
      "|One night six yea...|s3://taller4/tall...|\n",
      "|After the bullet ...|s3://taller4/tall...|\n",
      "|The Season 7 “Rea...|s3://taller4/tall...|\n",
      "|On the night of N...|s3://taller4/tall...|\n",
      "|WASHINGTON  —   O...|s3://taller4/tall...|\n",
      "|Canada, our No. 1...|s3://taller4/tall...|\n",
      "|A   of   lead exp...|s3://taller4/tall...|\n",
      "|Updated: 11:50 p....|s3://taller4/tall...|\n",
      "|• Hundreds of tho...|s3://taller4/tall...|\n",
      "|Thousands of year...|s3://taller4/tall...|\n",
      "|GLEN ELDER, Kan. ...|s3://taller4/tall...|\n",
      "|Danny Cahill stoo...|s3://taller4/tall...|\n",
      "|They called him t...|s3://taller4/tall...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "\n",
    "from  pyspark.sql.functions import input_file_name\n",
    "df3 = spark.read.text('s3://'+bucketName+'/tallerTextMining/inputs/contents/*.txt')\n",
    "df3 = df3.withColumn(\"filename\", input_file_name())\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52337bab058456d99a1327f67c9f63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed:  907.1658599376678"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "dic = {k:v for k,v in vectors.collect()}\n",
    "for fname in df3.rdd.collect():\n",
    "    rdd = sc.parallelize([fname['value']])\n",
    "    centroid_in = list(rdd.map(lambda x: [dic[w] if w in dic.keys() else [0.0,0.0,0.0,0.0,0.0] for w in x.lower().split(' ')]).map(lambda x: np.mean(x, axis=0)).collect()[0])\n",
    "    out_dict = { fname['filename'] : centroid_in}\n",
    "    json_file = '/inputs/centroids/' + fname['filename'].split('/')[-2].replace('.txt', '.json')\n",
    "    if not fs.exists(Path('s3://'+bucketName+'/tallerTextMining'+json_file)):\n",
    "        sc.parallelize([json.dumps(out_dict)]).saveAsTextFile('s3://'+bucketName+'/tallerTextMining/'+json_file)\n",
    "    #write_s3file(json_file, json.dumps(out_dict))\n",
    "print('time elapsed: ', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb25a035dbe4472a3eb79ade9fc48a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sents = [(s,) for s in sentences]\n",
    "df4 = spark.createDataFrame(sents)\n",
    "dictionary = df4.rdd.map(lambda x: x[0]).reduce(lambda x,y: list(np.unique(list(x)+list(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d2f1ead8064ee7926d1833eef91cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "centroid_dict = {}\n",
    "dfCentroide = spark.read.text('s3://'+bucketName+'/tallerTextMining/inputs/centroids/*.json')\n",
    "for fname in dfCentroide.rdd.collect():\n",
    "    d = json.loads(fname['value'])\n",
    "    centroid_dict.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9122273d2e4b25a4bc3c1d416dc7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_centroid_dict = {k: centroid_dict[k] for k in centroid_dict if not np.isnan(centroid_dict[k][0]).any()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35b57a78b4c414b813be70f0c788637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_embedding(x, out=False):\n",
    "    if x in dictionary:\n",
    "        return vectors.filter(vectors.word == x).select('vector').collect()[0]['vector']\n",
    "    else:\n",
    "        return np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee71f9176564f84b82fcb153063856c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "def score_document(q_embeddings, d_centroid):\n",
    "    individual_csims = [(1 - spatial.distance.cosine(qin, d_centroid)) for qin in q_embeddings]\n",
    "    return (sum(individual_csims)/len(q_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6480598e2a474a4eb8ef99c55bbdfb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = []\n",
    "df5 = spark.read.text('s3://'+bucketName+'/tallerTextMining//inputs/contents/*.txt')\n",
    "for fname in df5.rdd.collect():\n",
    "    documents.append(nltk.word_tokenize(fname['value'].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9f4010d54d47c59dd8ac862efe10c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num words in query:  3 Num query word in vectors:  3"
     ]
    }
   ],
   "source": [
    "query = 'mother buys meat'\n",
    "query_words = nltk.word_tokenize(query.lower())\n",
    "query_ins = [get_embedding(x) for x in query_words]\n",
    "q_len = len(query_ins)\n",
    "print('Num words in query: ', len(query_words), 'Num query word in vectors: ', q_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d1a51fcbca4debb00ac5aa9760b9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/1574283488638-0/local/lib64/python3.6/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)"
     ]
    }
   ],
   "source": [
    "scores_in_in = []\n",
    "for k,v in clean_centroid_dict.items():\n",
    "    scores_in_in.append((k, score_document(query_ins, v[0])))\n",
    "\n",
    "scores_in_in = sorted(scores_in_in, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f991ae4a010349e6913cd370f7d1ae85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 5 IN-IN:\n",
      "772.txt\n",
      "267.txt\n",
      "545.txt\n",
      "926.txt\n",
      "936.txt"
     ]
    }
   ],
   "source": [
    "print('TOP 5 IN-IN:')\n",
    "top_5_in_in = [x[0] for x in scores_in_in[:5]]\n",
    "\n",
    "for fname in top_5_in_in:\n",
    "    print(fname.split('/')[-2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
